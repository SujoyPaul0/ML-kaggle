{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Most machine learning libraries (including scikit-learn) give an error if you try to build a model using data with missing values. So you'll need to choose one of the strategies below."
      ],
      "metadata": {
        "id": "akOgixbCyFTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Three Approaches\n",
        "\n",
        "\n",
        "\n",
        "1.   A Simple Option: Drop Columns with Missing Values\n",
        "2.   A Better Option: Imputation\n",
        "3.   An Extension To Imputation\n"
      ],
      "metadata": {
        "id": "bXLGOd1GyM8P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YyXxckmqx5IH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/melb_data.csv')\n",
        "\n",
        "# Select target\n",
        "y = data.Price\n",
        "\n",
        "# To keep things simple, we'll use only numerical predictors\n",
        "melb_predictors = data.drop(['Price'], axis=1)\n",
        "X = melb_predictors.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                      random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Function to Measure Quality of Each Approach**"
      ],
      "metadata": {
        "id": "IvkNI5GM0-7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function for comparing different approaches\n",
        "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
        "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return mean_absolute_error(y_valid, preds)"
      ],
      "metadata": {
        "id": "lEHqEDvw1Clf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Score from Approach 1 (Drop Columns with Missing Values)**"
      ],
      "metadata": {
        "id": "1IpqDmXm1VOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get names of columns with missing values\n",
        "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
        "\n",
        "# Drop columns in training and validation data\n",
        "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
        "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
        "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhiIXyCq1X-L",
        "outputId": "ab56445c-f9ae-4279-8481-3d1b6f7a6754"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 1 (Drop columns with missing values):\n",
            "183550.22137772635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Score from Approach 1 (Drop Columns with Missing Values)**"
      ],
      "metadata": {
        "id": "dbZnahkd1-JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Imputation\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
        "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "imputed_X_train.columns = X_train.columns\n",
        "imputed_X_valid.columns = X_valid.columns\n",
        "\n",
        "print(\"MAE from Approach 2 (Imputation):\")\n",
        "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPHFaUhG12gp",
        "outputId": "460da93b-a952-4cd7-8f1a-cb5de1c25bdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 2 (Imputation):\n",
            "178166.46269899711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Score from Approach 3 (An Extension to Imputation)**"
      ],
      "metadata": {
        "id": "Bc7dK2Fw2jgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make copy to avoid changing original data (when imputing)\n",
        "X_train_plus = X_train.copy()\n",
        "X_valid_plus = X_valid.copy()\n",
        "\n",
        "# Make new columns indicating what will be imputed\n",
        "for col in cols_with_missing:\n",
        "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
        "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
        "\n",
        "# Imputation\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
        "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "imputed_X_train_plus.columns = X_train_plus.columns\n",
        "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
        "\n",
        "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
        "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJWWt7TJ2lLJ",
        "outputId": "4e023d77-21c7-448f-bee3-b846b01651d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 3 (An Extension to Imputation):\n",
            "178927.503183954\n"
          ]
        }
      ]
    }
  ]
}